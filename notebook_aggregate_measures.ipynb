{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b889fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "\n",
    "import util_localization_psychophysics\n",
    "\n",
    "tqdm.tqdm.pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd22afc2-99a1-4f70-b12d-3341a4d3fc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed experiment `maa_azimuth` for 10 `models/sound_localization/IHC3000_delayed_integration/arch??` models\n",
      "Completed experiment `maa_azimuth` for 10 `models/sound_localization/IHC3000/arch??` models\n",
      "Completed experiment `maa_azimuth` for 10 `models/sound_localization/IHC1000/arch??` models\n",
      "Completed experiment `maa_azimuth` for 10 `models/sound_localization/IHC0320/arch??` models\n",
      "Completed experiment `maa_azimuth` for 10 `models/sound_localization/IHC0050/arch??` models\n",
      "Completed experiment `maa_azimuth` for 10 `models/sound_localization/simplified_IHC3000_delayed_integration/arch??` models\n",
      "Completed experiment `maa_azimuth` for 10 `models/sound_localization/simplified_IHC3000/arch??` models\n",
      "Completed experiment `maa_azimuth` for 10 `models/sound_localization/simplified_IHC1000/arch??` models\n",
      "Completed experiment `maa_azimuth` for 10 `models/sound_localization/simplified_IHC0320/arch??` models\n",
      "Completed experiment `maa_azimuth` for 10 `models/sound_localization/simplified_IHC0050/arch??` models\n",
      "Completed experiment `itd_threshold` for 10 `models/sound_localization/IHC3000_delayed_integration/arch??` models\n",
      "Completed experiment `itd_threshold` for 10 `models/sound_localization/IHC3000/arch??` models\n",
      "Completed experiment `itd_threshold` for 10 `models/sound_localization/IHC1000/arch??` models\n",
      "Completed experiment `itd_threshold` for 10 `models/sound_localization/IHC0320/arch??` models\n",
      "Completed experiment `itd_threshold` for 10 `models/sound_localization/IHC0050/arch??` models\n",
      "Completed experiment `itd_threshold` for 10 `models/sound_localization/simplified_IHC3000_delayed_integration/arch??` models\n",
      "Completed experiment `itd_threshold` for 10 `models/sound_localization/simplified_IHC3000/arch??` models\n",
      "Completed experiment `itd_threshold` for 10 `models/sound_localization/simplified_IHC1000/arch??` models\n",
      "Completed experiment `itd_threshold` for 10 `models/sound_localization/simplified_IHC0320/arch??` models\n",
      "Completed experiment `itd_threshold` for 10 `models/sound_localization/simplified_IHC0050/arch??` models\n",
      "Completed experiment `itd_ild_weighting` for 10 `models/sound_localization/IHC3000_delayed_integration/arch??` models\n",
      "Completed experiment `itd_ild_weighting` for 10 `models/sound_localization/IHC3000/arch??` models\n",
      "Completed experiment `itd_ild_weighting` for 10 `models/sound_localization/IHC1000/arch??` models\n",
      "Completed experiment `itd_ild_weighting` for 10 `models/sound_localization/IHC0320/arch??` models\n",
      "Completed experiment `itd_ild_weighting` for 10 `models/sound_localization/IHC0050/arch??` models\n",
      "Completed experiment `itd_ild_weighting` for 10 `models/sound_localization/simplified_IHC3000_delayed_integration/arch??` models\n",
      "Completed experiment `itd_ild_weighting` for 10 `models/sound_localization/simplified_IHC3000/arch??` models\n",
      "Completed experiment `itd_ild_weighting` for 10 `models/sound_localization/simplified_IHC1000/arch??` models\n",
      "Completed experiment `itd_ild_weighting` for 10 `models/sound_localization/simplified_IHC0320/arch??` models\n",
      "Completed experiment `itd_ild_weighting` for 10 `models/sound_localization/simplified_IHC0050/arch??` models\n",
      "Completed experiment `spectral_smoothing` for 10 `models/sound_localization/IHC3000_delayed_integration/arch??` models\n",
      "Completed experiment `spectral_smoothing` for 10 `models/sound_localization/IHC3000/arch??` models\n",
      "Completed experiment `spectral_smoothing` for 10 `models/sound_localization/IHC1000/arch??` models\n",
      "Completed experiment `spectral_smoothing` for 10 `models/sound_localization/IHC0320/arch??` models\n",
      "Completed experiment `spectral_smoothing` for 10 `models/sound_localization/IHC0050/arch??` models\n",
      "Completed experiment `spectral_smoothing` for 10 `models/sound_localization/simplified_IHC3000_delayed_integration/arch??` models\n",
      "Completed experiment `spectral_smoothing` for 10 `models/sound_localization/simplified_IHC3000/arch??` models\n",
      "Completed experiment `spectral_smoothing` for 10 `models/sound_localization/simplified_IHC1000/arch??` models\n",
      "Completed experiment `spectral_smoothing` for 10 `models/sound_localization/simplified_IHC0320/arch??` models\n",
      "Completed experiment `spectral_smoothing` for 10 `models/sound_localization/simplified_IHC0050/arch??` models\n",
      "Completed experiment `precedence_effect_localization` for 10 `models/sound_localization/IHC3000_delayed_integration/arch??` models\n",
      "Completed experiment `precedence_effect_localization` for 10 `models/sound_localization/IHC3000/arch??` models\n",
      "Completed experiment `precedence_effect_localization` for 10 `models/sound_localization/IHC1000/arch??` models\n",
      "Completed experiment `precedence_effect_localization` for 10 `models/sound_localization/IHC0320/arch??` models\n",
      "Completed experiment `precedence_effect_localization` for 10 `models/sound_localization/IHC0050/arch??` models\n",
      "Completed experiment `precedence_effect_localization` for 10 `models/sound_localization/simplified_IHC3000_delayed_integration/arch??` models\n",
      "Completed experiment `precedence_effect_localization` for 10 `models/sound_localization/simplified_IHC3000/arch??` models\n",
      "Completed experiment `precedence_effect_localization` for 10 `models/sound_localization/simplified_IHC1000/arch??` models\n",
      "Completed experiment `precedence_effect_localization` for 10 `models/sound_localization/simplified_IHC0320/arch??` models\n",
      "Completed experiment `precedence_effect_localization` for 10 `models/sound_localization/simplified_IHC0050/arch??` models\n",
      "Completed experiment `new_ears` for 10 `models/sound_localization/IHC3000_delayed_integration/arch??` models\n",
      "Completed experiment `new_ears` for 10 `models/sound_localization/IHC3000/arch??` models\n",
      "Completed experiment `new_ears` for 10 `models/sound_localization/IHC1000/arch??` models\n",
      "Completed experiment `new_ears` for 10 `models/sound_localization/IHC0320/arch??` models\n",
      "Completed experiment `new_ears` for 10 `models/sound_localization/IHC0050/arch??` models\n",
      "Completed experiment `new_ears` for 10 `models/sound_localization/simplified_IHC3000_delayed_integration/arch??` models\n",
      "Completed experiment `new_ears` for 10 `models/sound_localization/simplified_IHC3000/arch??` models\n",
      "Completed experiment `new_ears` for 10 `models/sound_localization/simplified_IHC1000/arch??` models\n",
      "Completed experiment `new_ears` for 10 `models/sound_localization/simplified_IHC0320/arch??` models\n",
      "Completed experiment `new_ears` for 10 `models/sound_localization/simplified_IHC0050/arch??` models\n",
      "Completed experiment `bandwidth_dependency` for 10 `models/sound_localization/IHC3000_delayed_integration/arch??` models\n",
      "Completed experiment `bandwidth_dependency` for 10 `models/sound_localization/IHC3000/arch??` models\n",
      "Completed experiment `bandwidth_dependency` for 10 `models/sound_localization/IHC1000/arch??` models\n",
      "Completed experiment `bandwidth_dependency` for 10 `models/sound_localization/IHC0320/arch??` models\n",
      "Completed experiment `bandwidth_dependency` for 10 `models/sound_localization/IHC0050/arch??` models\n",
      "Completed experiment `bandwidth_dependency` for 10 `models/sound_localization/simplified_IHC3000_delayed_integration/arch??` models\n",
      "Completed experiment `bandwidth_dependency` for 10 `models/sound_localization/simplified_IHC3000/arch??` models\n",
      "Completed experiment `bandwidth_dependency` for 10 `models/sound_localization/simplified_IHC1000/arch??` models\n",
      "Completed experiment `bandwidth_dependency` for 10 `models/sound_localization/simplified_IHC0320/arch??` models\n",
      "Completed experiment `bandwidth_dependency` for 10 `models/sound_localization/simplified_IHC0050/arch??` models\n",
      "Completed experiment `mp_spectral_cues` for 10 `models/sound_localization/IHC3000_delayed_integration/arch??` models\n",
      "Completed experiment `mp_spectral_cues` for 10 `models/sound_localization/IHC3000/arch??` models\n",
      "Completed experiment `mp_spectral_cues` for 10 `models/sound_localization/IHC1000/arch??` models\n",
      "Completed experiment `mp_spectral_cues` for 10 `models/sound_localization/IHC0320/arch??` models\n",
      "Completed experiment `mp_spectral_cues` for 10 `models/sound_localization/IHC0050/arch??` models\n",
      "Completed experiment `mp_spectral_cues` for 10 `models/sound_localization/simplified_IHC3000_delayed_integration/arch??` models\n",
      "Completed experiment `mp_spectral_cues` for 10 `models/sound_localization/simplified_IHC3000/arch??` models\n",
      "Completed experiment `mp_spectral_cues` for 10 `models/sound_localization/simplified_IHC1000/arch??` models\n",
      "Completed experiment `mp_spectral_cues` for 10 `models/sound_localization/simplified_IHC0320/arch??` models\n",
      "Completed experiment `mp_spectral_cues` for 10 `models/sound_localization/simplified_IHC0050/arch??` models\n",
      "Completed experiment `snr_dependency` for 10 `models/sound_localization/IHC3000_delayed_integration/arch??` models\n",
      "Completed experiment `snr_dependency` for 10 `models/sound_localization/IHC3000/arch??` models\n",
      "Completed experiment `snr_dependency` for 10 `models/sound_localization/IHC1000/arch??` models\n",
      "Completed experiment `snr_dependency` for 10 `models/sound_localization/IHC0320/arch??` models\n",
      "Completed experiment `snr_dependency` for 10 `models/sound_localization/IHC0050/arch??` models\n",
      "Completed experiment `snr_dependency` for 10 `models/sound_localization/simplified_IHC3000_delayed_integration/arch??` models\n",
      "Completed experiment `snr_dependency` for 10 `models/sound_localization/simplified_IHC3000/arch??` models\n",
      "Completed experiment `snr_dependency` for 10 `models/sound_localization/simplified_IHC1000/arch??` models\n",
      "Completed experiment `snr_dependency` for 10 `models/sound_localization/simplified_IHC0320/arch??` models\n",
      "Completed experiment `snr_dependency` for 10 `models/sound_localization/simplified_IHC0050/arch??` models\n",
      "Completed experiment `speech_in_noise_in_reverb` for 10 `models/sound_localization/IHC3000_delayed_integration/arch??` models\n",
      "Completed experiment `speech_in_noise_in_reverb` for 10 `models/sound_localization/IHC3000/arch??` models\n",
      "Completed experiment `speech_in_noise_in_reverb` for 10 `models/sound_localization/IHC1000/arch??` models\n",
      "Completed experiment `speech_in_noise_in_reverb` for 10 `models/sound_localization/IHC0320/arch??` models\n",
      "Completed experiment `speech_in_noise_in_reverb` for 10 `models/sound_localization/IHC0050/arch??` models\n",
      "Completed experiment `speech_in_noise_in_reverb` for 10 `models/sound_localization/simplified_IHC3000_delayed_integration/arch??` models\n",
      "Completed experiment `speech_in_noise_in_reverb` for 10 `models/sound_localization/simplified_IHC3000/arch??` models\n",
      "Completed experiment `speech_in_noise_in_reverb` for 10 `models/sound_localization/simplified_IHC1000/arch??` models\n",
      "Completed experiment `speech_in_noise_in_reverb` for 10 `models/sound_localization/simplified_IHC0320/arch??` models\n",
      "Completed experiment `speech_in_noise_in_reverb` for 10 `models/sound_localization/simplified_IHC0050/arch??` models\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Run all sound localization experiments.\n",
    "\n",
    "`list_regex_dir_model` is a list of model conditions\n",
    "(different phase locking limits / cochlear models).\n",
    "\n",
    "Each directory included must contain the model evaluation\n",
    "output files for each psychophysical stimulus dataset (all\n",
    "model predictions, output probabilities, and stimulus data).\n",
    "\"\"\"\n",
    "\n",
    "list_regex_dir_model = [\n",
    "    \"models/sound_localization/IHC3000_delayed_integration/arch??\",\n",
    "    \"models/sound_localization/IHC3000/arch??\",\n",
    "    \"models/sound_localization/IHC1000/arch??\",\n",
    "    \"models/sound_localization/IHC0320/arch??\",\n",
    "    \"models/sound_localization/IHC0050/arch??\",\n",
    "    \"models/sound_localization/simplified_IHC3000_delayed_integration/arch??\",\n",
    "    \"models/sound_localization/simplified_IHC3000/arch??\",\n",
    "    \"models/sound_localization/simplified_IHC1000/arch??\",\n",
    "    \"models/sound_localization/simplified_IHC0320/arch??\",\n",
    "    \"models/sound_localization/simplified_IHC0050/arch??\",\n",
    "]\n",
    "\n",
    "EXPERIMENT_DATAFRAMES = util_localization_psychophysics.run_localization_experiments(\n",
    "    list_regex_dir_model,\n",
    "    workers=60,\n",
    "    dir_human_data='data/human/sound_localization',\n",
    "    tag_ckpt='',\n",
    "    func_label_to_azim_elev=util_localization_psychophysics.label_to_azim_elev,\n",
    "    key_pred_prob='label_loc_int:probs_out',\n",
    "    key_pred='label_loc_int:labels_pred',\n",
    "    key_true='label_loc_int:labels_true',\n",
    "    n_loc_classes=504,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4c1b36f-40b5-4904-a287-050c70750220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: data/model/sound_localization.pkl\n",
      "Wrote: data/model/sound_localization/maa_azimuth.csv\n",
      "Wrote: data/model/sound_localization/itd_threshold.csv\n",
      "Wrote: data/model/sound_localization/itd_ild_weighting.csv\n",
      "Wrote: data/model/sound_localization/spectral_smoothing.csv\n",
      "Wrote: data/model/sound_localization/precedence_effect_localization.csv\n",
      "Wrote: data/model/sound_localization/new_ears.csv\n",
      "Wrote: data/model/sound_localization/bandwidth_dependency.csv\n",
      "Wrote: data/model/sound_localization/mp_spectral_cues.csv\n",
      "Wrote: data/model/sound_localization/snr_dependency.csv\n",
      "Wrote: data/model/sound_localization/speech_in_noise_in_reverb.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Save sound localization experiment data to files.\n",
    "\n",
    "A dictionary of all experiment results is saved to\n",
    "a single pickle file. Individual experiment results\n",
    "are also saved to separate CSV files.\n",
    "\"\"\"\n",
    "\n",
    "fn_data = 'data/model/sound_localization.pkl'\n",
    "with open(fn_data, 'wb') as f:\n",
    "    pickle.dump(EXPERIMENT_DATAFRAMES, f)\n",
    "print(f\"Wrote: {fn_data}\")\n",
    "\n",
    "for tag_expt in EXPERIMENT_DATAFRAMES.keys():\n",
    "    fn_data_expt = fn_data.replace('.pkl', f'/{tag_expt}.csv')\n",
    "    EXPERIMENT_DATAFRAMES[tag_expt].to_csv(fn_data_expt, index=False)\n",
    "    print(f\"Wrote: {fn_data_expt}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7dfac57-69b6-48fd-bbae-ccb094ff8590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: data/model/sound_localization/speech_in_noise_in_reverb.csv\n",
      "|__ maa_azimuth\n",
      "|__ itd_threshold\n",
      "|__ itd_ild_weighting\n",
      "|__ spectral_smoothing\n",
      "|__ precedence_effect_localization\n",
      "|__ new_ears\n",
      "|__ bandwidth_dependency\n",
      "|__ mp_spectral_cues\n",
      "|__ snr_dependency\n",
      "|__ speech_in_noise_in_reverb\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load all sound localization experiment data.\n",
    "\"\"\"\n",
    "\n",
    "fn_data = 'data/model/sound_localization.pkl'\n",
    "with open(fn_data, 'rb') as f:\n",
    "    EXPERIMENT_DATAFRAMES = pickle.load(f)\n",
    "print(f\"Loaded: {fn_data_expt}\")\n",
    "for tag_expt in EXPERIMENT_DATAFRAMES.keys():\n",
    "    print(f\"|__ {tag_expt}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fcbc5a9-17e6-4c73-ad5b-1d51ed9cb070",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|██████████████▉                                                                                                                                      | 1/10 [00:18<02:47, 18.59s/it]/om2/user/msaddler/.conda/envs/tf/lib/python3.11/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "/om2/user/msaddler/.conda/envs/tf/lib/python3.11/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [02:52<00:00, 17.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag_expt='speech_in_noise_in_reverb'` not recognized --> returning None\n",
      "Wrote: data/model/sound_localization_human_model_comparison_metrics.pkl\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Calculate human-model comparison metrics for\n",
    "all sound localization experiments and save\n",
    "output to a file.\n",
    "\"\"\"\n",
    "\n",
    "def rmse(x, y):\n",
    "    return np.linalg.norm(x - y) / np.sqrt(x.shape[0])\n",
    "\n",
    "dict_metric_function = {\n",
    "    'pearsonr': scipy.stats.pearsonr,\n",
    "    'rmse': rmse,\n",
    "}\n",
    "\n",
    "df_results = []\n",
    "for tag_expt in tqdm.tqdm(EXPERIMENT_DATAFRAMES.keys()):\n",
    "    df = EXPERIMENT_DATAFRAMES[tag_expt]\n",
    "    df_results_tmp = util_localization_psychophysics.compare_localization_experiment(\n",
    "        df,\n",
    "        tag_expt=tag_expt,\n",
    "        dict_metric_function=dict_metric_function,\n",
    "        bootstrap_repeats=1000,\n",
    "        workers=60)\n",
    "    if df_results_tmp is not None:\n",
    "        df_results.append(df_results_tmp)\n",
    "df_results = pd.concat(df_results)\n",
    "\n",
    "fn_metrics = 'data/model/sound_localization_human_model_comparison_metrics.pkl'\n",
    "df_results.to_pickle(fn_metrics)\n",
    "print(f\"Wrote: {fn_metrics}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0544d2f8-8346-447f-9e9a-5b65237b235c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a78f26-3e2e-461e-aa39-345d7dfc57e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8763c083-8981-43cc-97f2-048acdafd6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = 'data/human/word_spkr_recognition/word_and_spkr_recognition_with_pitch_altered_speech.pkl'\n",
    "df = pd.read_pickle(fn)\n",
    "\n",
    "df_spkr = df[['condition', 'correct_spkr_list', 'f0_shift_in_semitones', 'tag_expt', 'tag_model']]\n",
    "df_spkr = df_spkr.rename(columns={'correct_spkr_list': 'correct_spkr'})\n",
    "df_word = df[['condition', 'correct_word_list', 'f0_shift_in_semitones', 'tag_expt', 'tag_model']]\n",
    "df_word = df_word.rename(columns={'correct_word_list': 'correct_word'})\n",
    "\n",
    "df_spkr['fn_eval'] = df_spkr['correct_spkr'].map(lambda l: ['spkr_participant_{:04d}'.format(_) for _ in range(len(l))])\n",
    "df_spkr = df_spkr.explode(['fn_eval', 'correct_spkr'])\n",
    "\n",
    "df_word['fn_eval'] = df_word['correct_word'].map(lambda l: ['word_participant_{:04d}'.format(_) for _ in range(len(l))])\n",
    "df_word = df_word.explode(['fn_eval', 'correct_word'])\n",
    "\n",
    "df = pd.concat([df_spkr, df_word])\n",
    "df = df.reindex(sorted(df.columns), axis=1)\n",
    "df.to_csv(fn.replace('.pkl', '.csv'), index=False)\n",
    "\n",
    "# df.groupby(['condition', 'f0_shift_in_semitones']).agg({\n",
    "#     'correct_spkr': list,\n",
    "#     'correct_word': list,\n",
    "#     'fn_eval': list,\n",
    "# }).reset_index(drop=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f495cde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(util_spkr_word_psychophysics)\n",
    "\n",
    "list_regex_dir_model = [\n",
    "    'saved_models/augmented_2022JAN/taskSW/IHC3000Hz_anf384H160M096L/arch0_00??',\n",
    "    'saved_models/augmented_2022JAN/taskSW/IHC1000Hz_anf384H160M096L/arch0_00??',\n",
    "    'saved_models/augmented_2022JAN/taskSW/IHC0320Hz_anf384H160M096L/arch0_00??',\n",
    "    'saved_models/augmented_2022JAN/taskSW/IHC0050Hz_anf384H160M096L/arch0_00??',\n",
    "    'saved_models/augmented_2022JAN/taskSW/spont0_simplified_IHC3000/arch0_00??',\n",
    "    'saved_models/augmented_2022JAN/taskSW/spont0_simplified_IHC1000/arch0_00??',\n",
    "    'saved_models/augmented_2022JAN/taskSW/spont0_simplified_IHC0320/arch0_00??',\n",
    "    'saved_models/augmented_2022JAN/taskSW/spont0_simplified_IHC0050/arch0_00??',\n",
    "    'saved_models/augmented_2022JAN/task_S/IHC3000Hz_anf384H160M096L/arch0_00??',\n",
    "    'saved_models/augmented_2022JAN/task_S/IHC1000Hz_anf384H160M096L/arch0_00??',\n",
    "    'saved_models/augmented_2022JAN/task_S/IHC0320Hz_anf384H160M096L/arch0_00??',\n",
    "    'saved_models/augmented_2022JAN/task_S/IHC0050Hz_anf384H160M096L/arch0_00??',\n",
    "    'saved_models/augmented_2022JAN/task_W/IHC3000Hz_anf384H160M096L/arch0_00??',\n",
    "    'saved_models/augmented_2022JAN/task_W/IHC1000Hz_anf384H160M096L/arch0_00??',\n",
    "    'saved_models/augmented_2022JAN/task_W/IHC0320Hz_anf384H160M096L/arch0_00??',\n",
    "    'saved_models/augmented_2022JAN/task_W/IHC0050Hz_anf384H160M096L/arch0_00??',\n",
    "]\n",
    "\n",
    "dict_basename_eval = {\n",
    "    'kell_like_inharmonic': 'EVAL_word_recognition_human_experiment_v00_inharmonic_foreground60dbspl.json',\n",
    "    'kell_like': 'EVAL_word_recognition_human_experiment_v00_foreground60dbspl.json',\n",
    "    'speech_in_synthetic_textures': 'EVAL_word_recognition_speech_in_synthetic_textures.json',\n",
    "    'pitch_altered': 'EVAL_pitch_altered_v00.json',\n",
    "    'hopkins_moore_2009': 'EVAL_hopkins_moore_2009.json',\n",
    "    'spkr_discrimination_timit_ssn': 'EVAL_spkr_discrimination_timit_ssn.json',\n",
    "}\n",
    "\n",
    "EXPERIMENT_DATAFRAMES = util_spkr_word_psychophysics.run_spkr_word_experiments(\n",
    "    list_regex_dir_model,\n",
    "    dict_basename_eval=dict_basename_eval)\n",
    "\n",
    "for tag_experiment in EXPERIMENT_DATAFRAMES.keys():\n",
    "    df = EXPERIMENT_DATAFRAMES[tag_experiment]\n",
    "    print(f\"--> {tag_experiment} ({len(df)}) <--\")\n",
    "#     for c in df.columns:\n",
    "#         print(f\"|__ {c}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456ac38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_data = '/om2/user/msaddler/tfauditoryutil/paper_phaselocknet/data/model_data_spkr_word.pkl'\n",
    "with open(fn_data, 'wb') as f:\n",
    "    pickle.dump(EXPERIMENT_DATAFRAMES, f)\n",
    "\n",
    "with open(fn_data, 'rb') as f:\n",
    "    EXPERIMENT_DATAFRAMES = pickle.load(f)\n",
    "\n",
    "print(fn_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d91c960",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(util_spkr_word_psychophysics)\n",
    "\n",
    "def rmse(x, y):\n",
    "    return np.linalg.norm(x - y) / np.sqrt(x.shape[0])\n",
    "\n",
    "dict_metric_function = {\n",
    "    'pearsonr': scipy.stats.pearsonr,\n",
    "    # 'spearmanr': scipy.stats.spearmanr,\n",
    "    'rmse': rmse,\n",
    "}\n",
    "\n",
    "experiment_to_compfunc_map = {\n",
    "    'kell_like_word': functools.partial(\n",
    "        util_spkr_word_psychophysics.compare_word_recognition_kell_like,\n",
    "        restrict_conditions=[0, 1, 2, 3]),\n",
    "    'kell_like_word_dip_listening': functools.partial(\n",
    "        util_spkr_word_psychophysics.compare_word_recognition_kell_like,\n",
    "        restrict_conditions=[3, 4]),\n",
    "    'speech_in_synthetic_textures': functools.partial(\n",
    "        util_spkr_word_psychophysics.compare_word_recognition_speech_in_synthetic_textures),\n",
    "    'pitch_altered_spkr_word': functools.partial(\n",
    "        util_spkr_word_psychophysics.compare_recognition_pitch_altered, key_task=['spkr', 'word']),\n",
    "    'pitch_altered_word': functools.partial(\n",
    "        util_spkr_word_psychophysics.compare_recognition_pitch_altered, key_task='word'),\n",
    "    'pitch_altered_spkr': functools.partial(\n",
    "        util_spkr_word_psychophysics.compare_recognition_pitch_altered, key_task='spkr'),\n",
    "    'hopkins_moore_2009_word': functools.partial(\n",
    "        util_spkr_word_psychophysics.compare_word_recognition_hopkins_moore_2009),\n",
    "    'spkr_discrimination_timit_ssn': functools.partial(\n",
    "        util_spkr_word_psychophysics.compare_spkr_discrimination_timit_ssn),\n",
    "}\n",
    "\n",
    "\n",
    "def func_to_parallelize(tag_expt):\n",
    "    compfunc = experiment_to_compfunc_map[tag_expt]\n",
    "    tag_expt_for_dataframe = tag_expt\n",
    "    for suffix in ['_spkr', '_word', '_dip_listening']:\n",
    "        tag_expt_for_dataframe = tag_expt_for_dataframe.replace(suffix, '')\n",
    "    df = EXPERIMENT_DATAFRAMES[tag_expt_for_dataframe]\n",
    "    df_results = None\n",
    "    for metric_key, metric_function in dict_metric_function.items():\n",
    "        df_results_tmp = compfunc(\n",
    "            df,\n",
    "            bootstrap_repeats=1000,\n",
    "            metric_function=metric_function)\n",
    "        df_results_tmp = df_results_tmp.rename(columns={\n",
    "            'metric': metric_key,\n",
    "            'bootstrap_list_metric': f'bootstrap_list_{metric_key}',\n",
    "        })\n",
    "        df_results_tmp['tag_expt'] = tag_expt\n",
    "        if df_results is None:\n",
    "            df_results = df_results_tmp\n",
    "        else:\n",
    "            df_results = df_results.merge(df_results_tmp, on=['tag_expt', 'tag_model'])\n",
    "    return df_results\n",
    "\n",
    "\n",
    "with multiprocessing.Pool(60) as pool:\n",
    "    list_df_results = pool.map(func_to_parallelize, list(experiment_to_compfunc_map.keys()))\n",
    "df_results = pd.concat(list_df_results)\n",
    "\n",
    "fn_metrics = '/om2/user/msaddler/tfauditoryutil/paper_phaselocknet/data/human_model_comparison_metrics_spkr_word.pkl'\n",
    "df_results.to_pickle(fn_metrics)\n",
    "print(fn_metrics)\n",
    "\n",
    "dict_agg = {}\n",
    "for k in dict_metric_function.keys():\n",
    "    dict_agg[k] = 'mean'\n",
    "    dict_agg[f'bootstrap_list_{k}'] = list\n",
    "df_results_mean = df_results.groupby(['tag_model']).agg(dict_agg).reset_index()\n",
    "for k in df_results_mean.columns:\n",
    "    if 'bootstrap_list_' in k:\n",
    "        df_results_mean[k] = df_results_mean[k].map(lambda _: np.array(list(_)).mean(axis=0))\n",
    "df_results_mean['tag_expt'] = 'AVERAGE'\n",
    "df_results_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99b6926",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_results, df_results_mean])\n",
    "list_tag_expt = np.unique(df.tag_expt)\n",
    "list_tag_model = np.unique(df.tag_model)[::-1]\n",
    "list_tag_model = [_ for _ in list_tag_model if 'taskSW/spont0' in _]\n",
    "fig, ax = make_plot_aggregate_measures(\n",
    "    df,\n",
    "    str_ylabel=\"Human-model similarity\\n(PEARSON R with 95% CI)\",\n",
    "    list_tag_expt=list_tag_expt,\n",
    "    list_tag_model=list_tag_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb69aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(util_spkr_word_psychophysics_figures)\n",
    "\n",
    "list_tag_model = np.unique(df_results.tag_model.values)\n",
    "list_tag_model = ['human'] + list_regex_dir_model[:4]\n",
    "list_tag_expt = [\n",
    "    'kell_like_word',\n",
    "    'kell_like_word_dip_listening',\n",
    "    'speech_in_synthetic_textures',\n",
    "    'hopkins_moore_2009',\n",
    "    'pitch_shifted',\n",
    "    'pitch_condition',\n",
    "    'kell_like_spkr',\n",
    "    'kell_like_spkr_dip_listening',\n",
    "    'spkr_discrimination_timit_ssn',\n",
    "]\n",
    "\n",
    "map_tag_expt_to_plot_func = {\n",
    "    'kell_like_word': functools.partial(\n",
    "        util_spkr_word_psychophysics_figures.make_plot_kell_like_recognition,\n",
    "        key_task='word',\n",
    "        fontsize_legend=7,\n",
    "        restrict_background_condition=[2, 0, 3, 1]),\n",
    "    'kell_like_word_dip_listening': functools.partial(\n",
    "        util_spkr_word_psychophysics_figures.make_plot_kell_like_recognition,\n",
    "        key_task='word',\n",
    "        fontsize_legend=12,\n",
    "        restrict_background_condition=[4, 3]),\n",
    "    'speech_in_synthetic_textures': functools.partial(\n",
    "        util_spkr_word_psychophysics_figures.make_plot_speech_in_synthetic_textures),\n",
    "    'hopkins_moore_2009': util_spkr_word_psychophysics_figures.make_plot_hopkins_moore_2009_tfs_benefit,\n",
    "    'pitch_shifted': functools.partial(\n",
    "        util_spkr_word_psychophysics_figures.make_plot_pitch_shifted_recognition,\n",
    "        key_task=['word', 'spkr']),\n",
    "    'pitch_condition': functools.partial(\n",
    "        util_spkr_word_psychophysics_figures.make_plot_pitch_condition_recognition,\n",
    "        key_task=['word', 'spkr']),\n",
    "    'kell_like_spkr': functools.partial(\n",
    "        util_spkr_word_psychophysics_figures.make_plot_kell_like_recognition,\n",
    "        key_task='spkr',\n",
    "        fontsize_legend=7,\n",
    "        restrict_background_condition=[2, 0, 3, 1],\n",
    "        kwargs_plot_update={'ls': '--'}),\n",
    "    'kell_like_spkr_dip_listening': functools.partial(\n",
    "        util_spkr_word_psychophysics_figures.make_plot_kell_like_recognition,\n",
    "        key_task='spkr',\n",
    "        fontsize_legend=12,\n",
    "        restrict_background_condition=[4, 3],\n",
    "        kwargs_plot_update={'ls': '--'}),\n",
    "    'spkr_discrimination_timit_ssn': functools.partial(\n",
    "        util_spkr_word_psychophysics_figures.make_plot_voice_discrimination,\n",
    "        kwargs_plot_update={'ls': '--'})\n",
    "}\n",
    "\n",
    "nrows = len(list_tag_expt)\n",
    "ncols = len(list_tag_model)\n",
    "figsize = (3.5 * ncols, 3 * nrows)\n",
    "fig, ax_arr = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize)\n",
    "ax_arr = ax_arr.reshape([nrows, ncols])\n",
    "\n",
    "for r, tag_expt in enumerate(list_tag_expt):\n",
    "    tag_expt_for_dataframe = tag_expt\n",
    "    if 'pitch' in tag_expt:\n",
    "        tag_expt_for_dataframe = 'pitch_altered'\n",
    "    for suffix in ['_spkr', '_word', '_dip_listening']:\n",
    "        tag_expt_for_dataframe = tag_expt_for_dataframe.replace(suffix, '')\n",
    "    df = EXPERIMENT_DATAFRAMES[tag_expt_for_dataframe]\n",
    "    for c, tag_model in enumerate(list_tag_model):\n",
    "        ax = ax_arr[r, c]\n",
    "        color, _ = get_color_and_label_from_model_tag(tag_model)\n",
    "        map_tag_expt_to_plot_func[tag_expt](ax, df[df.tag_model == tag_model], color=color)\n",
    "        if c > 0:\n",
    "            ax.xaxis.label.set_color('w')\n",
    "            ax.yaxis.label.set_color('w')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b255321",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(util_spkr_word_psychophysics_figures)\n",
    "\n",
    "tag_expt = 'spkr_discrimination_timit_ssn'\n",
    "list_tag_model = ['human'] + list_regex_dir_model\n",
    "fig, ax = plt.subplots()\n",
    "for tag_model in list_tag_model:\n",
    "    df = EXPERIMENT_DATAFRAMES[tag_expt]\n",
    "    df = df[df.tag_model == tag_model]\n",
    "    color, _ = get_color_and_label_from_model_tag(tag_model)\n",
    "    util_spkr_word_psychophysics_figures.make_plot_voice_discrimination(\n",
    "        ax,\n",
    "        df[df.tag_model == tag_model],\n",
    "        color=color,\n",
    "        include_legend=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ac8541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36899795",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3328f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(util_localization_psychophysics)\n",
    "list_regex_dir_model = [\n",
    "    '/om2/user/msaddler/tfauditoryutil/saved_models/models_localize/v01/grouped/before_pool_factor2/IHC3000Hz_anf384H160M096L/archFrancl??',    \n",
    "    '/om2/user/msaddler/tfauditoryutil/saved_models/models_localize/v01/IHC3000Hz_anf384H160M096L/archFrancl??',\n",
    "    '/om2/user/msaddler/tfauditoryutil/saved_models/models_localize/v01/IHC1000Hz_anf384H160M096L/archFrancl??',\n",
    "    '/om2/user/msaddler/tfauditoryutil/saved_models/models_localize/v01/IHC0320Hz_anf384H160M096L/archFrancl??',\n",
    "    '/om2/user/msaddler/tfauditoryutil/saved_models/models_localize/v01/IHC0050Hz_anf384H160M096L/archFrancl??',\n",
    "    \n",
    "    '/om2/user/msaddler/tfauditoryutil/saved_models/models_localize/v01/grouped/before_pool_factor2/spont0_simplified_IHC3000/archFrancl??',\n",
    "    '/om2/user/msaddler/tfauditoryutil/saved_models/models_localize/v01/spont0_simplified_IHC3000/archFrancl??',\n",
    "    '/om2/user/msaddler/tfauditoryutil/saved_models/models_localize/v01/spont0_simplified_IHC1000/archFrancl??',\n",
    "    '/om2/user/msaddler/tfauditoryutil/saved_models/models_localize/v01/spont0_simplified_IHC0320/archFrancl??',\n",
    "    '/om2/user/msaddler/tfauditoryutil/saved_models/models_localize/v01/spont0_simplified_IHC0050/archFrancl??',\n",
    "]\n",
    "\n",
    "# EXPERIMENT_DATAFRAMES = util_localization_psychophysics.run_localization_experiments(\n",
    "#     list_regex_dir_model,\n",
    "#     func_label_to_azim_elev=util_localization_psychophysics.label_to_azim_elev,\n",
    "#     key_pred_prob='label_loc_int:probs_out',\n",
    "#     key_pred='label_loc_int:labels_pred',\n",
    "#     key_true='label_loc_int:labels_true',\n",
    "#     n_loc_classes=504,\n",
    "#     workers=60,\n",
    "#     tag_ckpt='',\n",
    "#     # list_expt=['speech_in_noise_in_reverb'],\n",
    "# )\n",
    "\n",
    "fn_data = '/om2/user/msaddler/tfauditoryutil/paper_phaselocknet/data/model_data_localization.pkl'\n",
    "\n",
    "# with open(fn_data, 'wb') as f:\n",
    "#     pickle.dump(EXPERIMENT_DATAFRAMES, f)\n",
    "# print(fn_data)\n",
    "\n",
    "with open(fn_data, 'rb') as f:\n",
    "    EXPERIMENT_DATAFRAMES = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2788961c",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(util_localization_psychophysics)\n",
    "\n",
    "def rmse(x, y):\n",
    "    return np.linalg.norm(x - y) / np.sqrt(x.shape[0])\n",
    "\n",
    "dict_metric_function = {\n",
    "    'pearsonr': scipy.stats.pearsonr,\n",
    "    # 'spearmanr': scipy.stats.spearmanr,\n",
    "    'rmse': rmse,\n",
    "}\n",
    "\n",
    "df_results = []\n",
    "for tag_expt in tqdm.tqdm(EXPERIMENT_DATAFRAMES.keys()):\n",
    "    df = EXPERIMENT_DATAFRAMES[tag_expt]\n",
    "    df_results_tmp = util_localization_psychophysics.compare_localization_experiment(\n",
    "        df,\n",
    "        tag_expt=tag_expt,\n",
    "        dict_metric_function=dict_metric_function,\n",
    "        bootstrap_repeats=1000,\n",
    "        workers=60)\n",
    "    if df_results_tmp is not None:\n",
    "        df_results.append(df_results_tmp)\n",
    "df_results = pd.concat(df_results)\n",
    "\n",
    "fn_metrics = '/om2/user/msaddler/tfauditoryutil/paper_phaselocknet/data/human_model_comparison_metrics_localization.pkl'\n",
    "df_results.to_pickle(fn_metrics)\n",
    "print(fn_metrics)\n",
    "\n",
    "dict_agg = {}\n",
    "for k in dict_metric_function.keys():\n",
    "    dict_agg[k] = 'mean'\n",
    "    dict_agg[f'bootstrap_list_{k}'] = list\n",
    "df_results_mean = df_results.groupby(['tag_model']).agg(dict_agg).reset_index()\n",
    "for k in df_results_mean.columns:\n",
    "    if 'bootstrap_list_' in k:\n",
    "        df_results_mean[k] = df_results_mean[k].map(lambda _: np.array(list(_)).mean(axis=0))\n",
    "df_results_mean['tag_expt'] = 'AVERAGE'\n",
    "df_results_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fe6d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_results, df_results_mean])\n",
    "list_tag_expt = [\n",
    "    'AVERAGE',\n",
    "#     'snr_dependency',\n",
    "#     'minimum_audible_angle',\n",
    "#     'itd_ild_weighting',\n",
    "#     'itd_threshold',\n",
    "#     'new_ears',\n",
    "#     'spectral_smoothing',\n",
    "#     'precedence_effect_localization',\n",
    "#     'mp_spectral_cues',\n",
    "#     'bandwidth_dependency',\n",
    "]\n",
    "# list_tag_expt = np.unique(df.tag_expt)\n",
    "list_tag_model = np.unique(df.tag_model)[::-1]\n",
    "# list_tag_model = [\n",
    "#     _ for _ in list_tag_model if ('3000' in _) or ('pool' in _)\n",
    "# ]\n",
    "fig, ax = make_plot_aggregate_measures(\n",
    "    df,\n",
    "    str_ylabel=\"Human-model similarity\\n(PEARSON R with 95% CI)\",\n",
    "    list_tag_expt=list_tag_expt,\n",
    "    list_tag_model=list_tag_model,\n",
    "    width=0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b68939",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb9fd5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7b77ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import util_pitchnet_psychophysics_figures\n",
    "importlib.reload(util_pitchnet_psychophysics_figures)\n",
    "\n",
    "list_regex_dir_model = [\n",
    "    'human',\n",
    "    '/om2/user/msaddler/tfauditoryutil/saved_models/PNDv08/IHC3000Hz_anf192H080M048L/arch_0???',\n",
    "    '/om2/user/msaddler/tfauditoryutil/saved_models/PNDv08/IHC1000Hz_anf192H080M048L/arch_0???',\n",
    "    '/om2/user/msaddler/tfauditoryutil/saved_models/PNDv08/TRANSPOSED_IHC0320Hz_anf019H008M005L/arch_0???',\n",
    "    '/om2/user/msaddler/tfauditoryutil/saved_models/PNDv08/TRANSPOSED_IHC0050Hz_anf019H008M005L/arch_0???',\n",
    "    '/om2/user/msaddler/tfauditoryutil/saved_models/PNDv08/spont0_simplified_IHC3000/arch_0???',\n",
    "    '/om2/user/msaddler/tfauditoryutil/saved_models/PNDv08/spont0_simplified_IHC1000/arch_0???',\n",
    "    '/om2/user/msaddler/tfauditoryutil/saved_models/PNDv08/spont0_simplified_IHC0320_TRANSPOSED/arch_0???',\n",
    "    '/om2/user/msaddler/tfauditoryutil/saved_models/PNDv08/spont0_simplified_IHC0050_TRANSPOSED/arch_0???',\n",
    "]\n",
    "\n",
    "experiment_to_func = {\n",
    "    'bernox2005': util_pitchnet_psychophysics_figures.load_data_bernox2005,\n",
    "    'mcpherson_snr': util_pitchnet_psychophysics_figures.load_data_mcpherson_snr,\n",
    "    'transposedtones': util_pitchnet_psychophysics_figures.load_data_transposedtones,\n",
    "    'pure_tone_spl': util_pitchnet_psychophysics_figures.load_data_pure_tone_spl,\n",
    "    'freqshiftedcomplexes': util_pitchnet_psychophysics_figures.load_data_freqshiftedcomplexes,\n",
    "    'mistunedharmonics': util_pitchnet_psychophysics_figures.load_data_mistunedharmonics,\n",
    "    'altphasecomplexes': lambda _: util_pitchnet_psychophysics_figures.load_data_altphasecomplexes(_, bin_step=0.04),\n",
    "}\n",
    "\n",
    "EXPERIMENT_DATAFRAMES = {}\n",
    "for tag_expt in experiment_to_func.keys():\n",
    "    print(tag_expt)\n",
    "    EXPERIMENT_DATAFRAMES[tag_expt] = experiment_to_func[tag_expt](list_regex_dir_model)\n",
    "\n",
    "fn_data = '/om2/user/msaddler/tfauditoryutil/paper_phaselocknet/data/model_data_pitchnet.pkl'\n",
    "with open(fn_data, 'wb') as f:\n",
    "    pickle.dump(EXPERIMENT_DATAFRAMES, f)\n",
    "with open(fn_data, 'rb') as f:\n",
    "    EXPERIMENT_DATAFRAMES = pickle.load(f)\n",
    "print(fn_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d70e74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(util_pitchnet_psychophysics_figures)\n",
    "\n",
    "def rmse(x, y):\n",
    "    return np.linalg.norm(x - y) / np.sqrt(x.shape[0])\n",
    "\n",
    "dict_metric_function = {\n",
    "    'pearsonr': scipy.stats.pearsonr,\n",
    "    # 'spearmanr': scipy.stats.spearmanr,\n",
    "    'rmse': rmse,\n",
    "}\n",
    "\n",
    "df_results = []\n",
    "for tag_expt in tqdm.tqdm(EXPERIMENT_DATAFRAMES.keys()):\n",
    "    df = EXPERIMENT_DATAFRAMES[tag_expt]\n",
    "    df_results_tmp = util_pitchnet_psychophysics_figures.compare_pitchnet_experiment(\n",
    "        df,\n",
    "        tag_expt=tag_expt,\n",
    "        dict_metric_function=dict_metric_function,\n",
    "        workers=40)\n",
    "    df_results.append(df_results_tmp)\n",
    "df_results = pd.concat(df_results)\n",
    "\n",
    "fn_metrics = '/om2/user/msaddler/tfauditoryutil/paper_phaselocknet/data/human_model_comparison_metrics_pitchnet.pkl'\n",
    "df_results.to_pickle(fn_metrics)\n",
    "print(fn_metrics)\n",
    "\n",
    "dict_agg = {}\n",
    "for k in dict_metric_function.keys():\n",
    "    dict_agg[k] = 'mean'\n",
    "    dict_agg[f'bootstrap_list_{k}'] = list\n",
    "df_results_mean = df_results.groupby(['tag_model']).agg(dict_agg).reset_index()\n",
    "for k in df_results_mean.columns:\n",
    "    if 'bootstrap_list_' in k:\n",
    "        df_results_mean[k] = df_results_mean[k].map(lambda _: np.array(list(_)).mean(axis=0))\n",
    "df_results_mean['tag_expt'] = 'AVERAGE'\n",
    "df_results_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adcd4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_results, df_results_mean])\n",
    "list_tag_expt = ['AVERAGE'] + list(EXPERIMENT_DATAFRAMES.keys())\n",
    "list_tag_model = np.unique(df['tag_model'].values)[::-1]\n",
    "# list_tag_model = [list_tag_model[_] for _ in [2,3,0,1]]\n",
    "\n",
    "for tag_model in list_tag_model:\n",
    "    print(tag_model)\n",
    "\n",
    "fig, ax = make_plot_aggregate_measures(\n",
    "    df,\n",
    "    str_ylabel=\"Human-model similarity\\n(PEARSON R with 95% CI)\",\n",
    "    width=0.15,\n",
    "#     key_metric='mae',\n",
    "#     str_ylabel=None,\n",
    "#     ylimits=None,\n",
    "#     yticks=None,\n",
    "    list_tag_expt=list_tag_expt,\n",
    "    list_tag_model=list_tag_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a3fd69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
