{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc2f936d-cbe8-4309-89ce-6837805345ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import h5py\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import util_cochlea\n",
    "import util_network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db4b2387-3f72-4c80-9eba-ad4b16df4335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model input shape: [40000]\n",
      "Model output shape(s): {'label_speaker_int': 433, 'label_word_int': 794}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Specify model directory and load config / architecture\n",
    "\"\"\"\n",
    "\n",
    "dir_model = 'models/spkr_word_recognition/simplified_IHC3000/arch0_0000'\n",
    "\n",
    "fn_config = os.path.join(dir_model, 'config.json')\n",
    "fn_arch = os.path.join(dir_model, 'arch.json')\n",
    "fn_ckpt = os.path.join(dir_model, 'ckpt_BEST')\n",
    "\n",
    "with open(fn_config, 'r') as f_config:\n",
    "    CONFIG = json.load(f_config)\n",
    "with open(fn_arch, 'r') as f_arch:\n",
    "    list_layer_dict = json.load(f_arch)\n",
    "n_classes_dict = CONFIG['n_classes_dict']\n",
    "\n",
    "if CONFIG.get('kwargs_cochlea', {}):\n",
    "    sr = CONFIG['kwargs_cochlea']['sr_input']\n",
    "    if 'localization' in dir_model:\n",
    "        input_shape = [int(1.3 * sr), 2] # 1.3-second binaural input for localization model\n",
    "    else:\n",
    "        input_shape = [int(2 * sr)] # 2-second monaural input for word + voice recognition model\n",
    "else:\n",
    "    if 'localization' in dir_model:\n",
    "        input_shape = [50, 10000, 3, 2] # Pre-generated nervegram (50 freq channels, 1-second at 10 kHz, 3 spont rates, binaural)\n",
    "    else:\n",
    "        input_shape = [50, 20000, 3] # Pre-generated nervegram (50 freq channels, 2-seconds at 10 kHz, 3 spont rates, monaural)\n",
    "\n",
    "print(f\"Model input shape: {input_shape}\")\n",
    "print(f\"Model output shape(s): {n_classes_dict}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b8239ed-1621-4c2f-9367-296c9d12ec2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-24 18:42:17.676902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11412 MB memory:  -> device: 0, name: TITAN Xp, pci bus id: 0000:05:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cochlea] converting audio to subbands using fir_gammatone_filterbank\n",
      "[cochlea] half-wave rectified subbands\n",
      "[tf_fir_resample] interpreted `tensor_input.shape` as [batch, freq=50, time=40000]\n",
      "[tf_fir_resample] `kwargs_fir_lowpass_filter`: {'cutoff': 3000, 'fir_dur': 0.05, 'ihc_filter': True, 'order': 7}\n",
      "[fir_lowpass_filter] sr_filt = 20000.0 Hz\n",
      "[fir_lowpass_filter] numtaps = 1001 samples\n",
      "[fir_lowpass_filter] fir_dur = 0.05 seconds\n",
      "[fir_lowpass_filter] cutoff = 3000 Hz\n",
      "[fir_lowpass_filter] order = 7 (bez2018model IHC filter)\n",
      "[cochlea] resampled subbands from 20000 Hz to 10000 Hz with filter: {'cutoff': 3000, 'fir_dur': 0.05, 'ihc_filter': True, 'order': 7}\n",
      "[cochlea] half-wave rectified resampled subbands\n",
      "[cochlea] incorporated sigmoid_rate_level_function: {'dynamic_range': [20.0, 40.0, 80.0], 'dynamic_range_interval': 0.95, 'envelope_mode': True, 'rate_max': [250.0, 250.0, 250.0], 'rate_spont': [0.0, 0.0, 0.0], 'threshold': [0.0, 12.0, 28.0]}\n",
      "[cochlea] inferring `sr=10000.0` for spike_generator_binomial\n",
      "[cochlea] incorporated spike_generator_binomial: {'mode': 'approx', 'n_per_channel': [384, 160, 96], 'sr': 10000.0}\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 40000)]              0         []                            \n",
      "                                                                                                  \n",
      " sequential (Sequential)     (None, 50, 20000, 3)         0         ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " input_reshape (Reshape)     (None, 50, 20000, 3)         0         ['sequential[2][0]']          \n",
      "                                                                                                  \n",
      " input_norm (LayerNormaliza  (None, 50, 20000, 3)         0         ['input_reshape[0][0]']       \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " tf.compat.v1.pad (TFOpLamb  (None, 51, 20000, 3)         0         ['input_norm[0][0]']          \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " block0_conv (Conv2D)        (None, 50, 19959, 32)        8096      ['tf.compat.v1.pad[0][0]']    \n",
      "                                                                                                  \n",
      " block0_relu (ReLU)          (None, 50, 19959, 32)        0         ['block0_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block0_pool (Lambda)        (None, 25, 4986, 32)         0         ['block0_relu[0][0]']         \n",
      "                                                                                                  \n",
      " block0_norm (LayerNormaliz  (None, 25, 4986, 32)         64        ['block0_pool[0][0]']         \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " tf.compat.v1.pad_1 (TFOpLa  (None, 26, 4986, 32)         0         ['block0_norm[0][0]']         \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " block1_conv (Conv2D)        (None, 25, 4969, 64)         73792     ['tf.compat.v1.pad_1[0][0]']  \n",
      "                                                                                                  \n",
      " block1_relu (ReLU)          (None, 25, 4969, 64)         0         ['block1_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block1_pool (Lambda)        (None, 13, 1239, 64)         0         ['block1_relu[0][0]']         \n",
      "                                                                                                  \n",
      " block1_norm (LayerNormaliz  (None, 13, 1239, 64)         128       ['block1_pool[0][0]']         \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " tf.compat.v1.pad_2 (TFOpLa  (None, 18, 1239, 64)         0         ['block1_norm[0][0]']         \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " block2_conv (Conv2D)        (None, 13, 1234, 128)        295040    ['tf.compat.v1.pad_2[0][0]']  \n",
      "                                                                                                  \n",
      " block2_relu (ReLU)          (None, 13, 1234, 128)        0         ['block2_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block2_pool (Lambda)        (None, 13, 305, 128)         0         ['block2_relu[0][0]']         \n",
      "                                                                                                  \n",
      " block2_norm (LayerNormaliz  (None, 13, 305, 128)         256       ['block2_pool[0][0]']         \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " tf.compat.v1.pad_3 (TFOpLa  (None, 18, 305, 128)         0         ['block2_norm[0][0]']         \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " block3_conv (Conv2D)        (None, 13, 300, 256)         1179904   ['tf.compat.v1.pad_3[0][0]']  \n",
      "                                                                                                  \n",
      " block3_relu (ReLU)          (None, 13, 300, 256)         0         ['block3_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block3_pool (Lambda)        (None, 13, 72, 256)          0         ['block3_relu[0][0]']         \n",
      "                                                                                                  \n",
      " block3_norm (LayerNormaliz  (None, 13, 72, 256)          512       ['block3_pool[0][0]']         \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " tf.compat.v1.pad_4 (TFOpLa  (None, 20, 72, 256)          0         ['block3_norm[0][0]']         \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " block4_conv (Conv2D)        (None, 13, 65, 512)          8389120   ['tf.compat.v1.pad_4[0][0]']  \n",
      "                                                                                                  \n",
      " block4_relu (ReLU)          (None, 13, 65, 512)          0         ['block4_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block4_pool (Lambda)        (None, 13, 65, 512)          0         ['block4_relu[0][0]']         \n",
      "                                                                                                  \n",
      " block4_norm (LayerNormaliz  (None, 13, 65, 512)          1024      ['block4_pool[0][0]']         \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " tf.compat.v1.pad_5 (TFOpLa  (None, 18, 65, 512)          0         ['block4_norm[0][0]']         \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " block5_conv (Conv2D)        (None, 13, 60, 512)          9437696   ['tf.compat.v1.pad_5[0][0]']  \n",
      "                                                                                                  \n",
      " block5_relu (ReLU)          (None, 13, 60, 512)          0         ['block5_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block5_pool (Lambda)        (None, 13, 60, 512)          0         ['block5_relu[0][0]']         \n",
      "                                                                                                  \n",
      " block5_norm (LayerNormaliz  (None, 13, 60, 512)          1024      ['block5_pool[0][0]']         \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " tf.compat.v1.pad_6 (TFOpLa  (None, 20, 60, 512)          0         ['block5_norm[0][0]']         \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " block6_conv (Conv2D)        (None, 13, 53, 512)          1677772   ['tf.compat.v1.pad_6[0][0]']  \n",
      "                                                          8                                       \n",
      "                                                                                                  \n",
      " block6_relu (ReLU)          (None, 13, 53, 512)          0         ['block6_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block6_pool (Lambda)        (None, 7, 10, 512)           0         ['block6_relu[0][0]']         \n",
      "                                                                                                  \n",
      " block6_norm (LayerNormaliz  (None, 7, 10, 512)           1024      ['block6_pool[0][0]']         \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " fc_flatten (Flatten)        (None, 35840)                0         ['block6_norm[0][0]']         \n",
      "                                                                                                  \n",
      " fc_intermediate_dense (Den  (None, 512)                  1835059   ['fc_flatten[0][0]']          \n",
      " se)                                                      2                                       \n",
      "                                                                                                  \n",
      " fc_intermediate_relu (ReLU  (None, 512)                  0         ['fc_intermediate_dense[0][0]'\n",
      " )                                                                  ]                             \n",
      "                                                                                                  \n",
      " fc_intermediate_norm (Laye  (None, 512)                  1024      ['fc_intermediate_relu[0][0]']\n",
      " rNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " fc_dropout (Dropout)        (None, 512)                  0         ['fc_intermediate_norm[0][0]']\n",
      "                                                                                                  \n",
      " fc_top_label_speaker_int (  (None, 433)                  222129    ['fc_dropout[0][0]']          \n",
      " Dense)                                                                                           \n",
      "                                                                                                  \n",
      " fc_top_label_word_int (Den  (None, 794)                  407322    ['fc_dropout[0][0]']          \n",
      " se)                                                                                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 55146475 (210.37 MB)\n",
      "Trainable params: 55146475 (210.37 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Build TensorFlow model object and load pre-trained weights\n",
    "\"\"\"\n",
    "\n",
    "def model_io_function(x):\n",
    "    y = x\n",
    "    if CONFIG.get('kwargs_cochlea', {}):\n",
    "        if 'label_loc_int' in n_classes_dict:\n",
    "            msg = \"expected [batch, freq, time, spont, channel=2] or [batch, time, channel=2]\"\n",
    "            assert (len(y.shape) in [3, 5]) and (y.shape[-1] == 2), msg\n",
    "            y0, _ = util_cochlea.cochlea(y[..., 0], **copy.deepcopy(CONFIG['kwargs_cochlea']))\n",
    "            y1, _ = util_cochlea.cochlea(y[..., 1], **copy.deepcopy(CONFIG['kwargs_cochlea']))\n",
    "            y = tf.concat([y0, y1], axis=-1)\n",
    "            if y.shape[2] > nervegram_slice_length:\n",
    "                y = util_cochlea.random_slice(\n",
    "                    y,\n",
    "                    slice_length=nervegram_slice_length,\n",
    "                    axis=2, # Time axis\n",
    "                    buffer=500)\n",
    "        else:\n",
    "            y, _ = util_cochlea.cochlea(y, **copy.deepcopy(CONFIG['kwargs_cochlea']))\n",
    "    y, _ = util_network.build_network(y, list_layer_dict, n_classes_dict=n_classes_dict)\n",
    "    return y\n",
    "\n",
    "inputs = tf.keras.Input(shape=input_shape, batch_size=None, dtype=tf.float32)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=model_io_function(inputs))\n",
    "model.load_weights(fn_ckpt)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21c028b0-bb6a-4826-8b5c-237b845ee7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch of example inputs: y.shape=(8, 40000) y.dtype=dtype('float32')\n",
      "|__ dur float64 [2. 2. 2. 2. 2. 2. 2. 2.]\n",
      "|__ index_example int64 [0 1 2 3 4 5 6 7]\n",
      "|__ index_foreground int64 [0 1 2 3 4 5 6 7]\n",
      "|__ index_texture int64 [0 0 0 0 0 0 0 0]\n",
      "|__ label_speaker_int int64 [204 279 225 287 364 364 263 265]\n",
      "|__ label_word_int int64 [ 3  5  7  8 10 11 13 14]\n",
      "|__ snr int64 [-3 -3 -3 -3 -3 -3 -3 -3]\n",
      "|__ sr int64 [20000 20000 20000 20000 20000 20000 20000 20000]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load stimuli on which to evaluate model\n",
    "\"\"\"\n",
    "\n",
    "fn_stim = 'stimuli/spkr_word_recognition/evaluation/speech_in_synthetic_textures/stim.hdf5'\n",
    "with h5py.File(fn_stim, 'r') as f:\n",
    "    batch_size = 8\n",
    "    idx0 = 0\n",
    "    indexes = slice(idx0, idx0 + batch_size)\n",
    "    y = f['signal'][indexes]\n",
    "    print(f\"Batch of example inputs: {y.shape=} {y.dtype=}\")\n",
    "    for k in f.keys():\n",
    "        if f[k].ndim == 1:\n",
    "            print('|__', k, f[k].dtype, f[k][indexes])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e1e8565-7e2b-4cc4-8d5d-aa5b1c529e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model outputs (softmax cross entropy logits):\n",
      "|__ label_speaker_int <dtype: 'float32'> (8, 433)\n",
      "|__ label_word_int <dtype: 'float32'> (8, 794)\n",
      "Model outputs (class label predictions):\n",
      "|__ label_speaker_int [204 279 225 214 364 364 263 264]\n",
      "|__ label_word_int [724   5 223   8 584  10  18  14]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Evaluate model on example stimuli\n",
    "\"\"\"\n",
    "\n",
    "out = model(y)\n",
    "\n",
    "print(\"Model outputs (softmax cross entropy logits):\")\n",
    "for k, v in out.items():\n",
    "    print('|__', k, v.dtype, v.shape)\n",
    "\n",
    "print(\"Model outputs (class label predictions):\")\n",
    "for k, v in out.items():\n",
    "    print('|__', k, np.argmax(v, axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dad50f9-3fc7-4c93-bbd6-48bf5ff4dd3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
